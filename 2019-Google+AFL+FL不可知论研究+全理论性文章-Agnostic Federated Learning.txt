2019-one shot-Agnostic Federated Learning

Google 纽约研究所的工作

摘要：
大规模应用程序中的关键学习场景是联合学习，其中基于源自大量客户端的数据来训练集中式模型。我们认为，通过现有的培训和推理，联合模型可以偏向不同的客户。相反，我们提出了一个新的不可知联邦学习框架，其中集中模型针对由客户端分布的混合形成的任何目标分布进行了优化。我们进一步表明，这个框架自然会产生一种公平的概念。我们提出了与数据相关的Rademacher复杂性保证，用于学习该目标，该目标指导了不可知联合学习算法的定义。我们还给出了一个快速随机优化算法来解决相应的优化问题，我们证明了收敛边界，假设凸损失函数和假设集。我们进一步凭经验证明了我们的方法在几个数据集中的优势。除了联合学习之外，我们的框架和算法可能对其他学习场景感兴趣，例如云计算，域适应，漂移以及训练和测试分布不一致的其他环境。


非常偏理论的文章，难懂，连实验都没有图表，就是纯文字说了一下

不可知联合学习框架：
针对客户端数据分布混合形成的任何目标分布进行了优化，该框架能够自然生成一个公平的概念


针对真实场景中FL受限的问题，主要是均匀分布不代表自然分布，提出AFL，对于由客户端分布混合行成的任何目标进行优化，而不是特定的模型，定义了不可知和更多抗风险目标。
他们表明，对于目标混合分布，通过最小化相对于均匀分布U获得的假设的交叉熵损失比在AFL上面更差，即学习者可以访问无限的样本大小。

还表明AFL会自然产生公平的概念


我们提出了一个新的不可知联邦学习框架（AFL），其中集中模型针对由客户端分布的混合形成的任何可能的目标分布进行了优化。我们不是优化特定分布的集中模型，而是与目标不匹配的高风险，而是定义一个不可知和更多风险厌恶的目标。我们表明，对于一些目标混合分布，通过最小化相对于均匀分布U获得的假设的交叉熵损失可以通过恒定的加法项比在AFL中获得的假设更差，即使学习者可以访问无限的样本大小（第3.2节）。
我们进一步表明，我们的AFL框架自然会产生一种公平的概念，我们称之为良好的公平性（第3.3节）。实际上，我们的AFL框架的优化问题的预测解决方案同样对待所有受保护的类别。除了联合学习之外，我们的框架和解决方案还涵盖了基于云的学习服务中的相关问题，客户可能无法获得任何培训数据，也可能不愿意与云共享该数据。在这种情况下，服务器也需要训练模型而无需访问训练数据。我们的框架和算法也可能对其他学习场景感兴趣，例如域适应，漂移和其他训练和测试分布不一致的上下文。



