2019-SecureBoost: A Lossless Federated Learning Framework

杨强+微众+加州大学等人工作

key idea：
多方设置+隐私安全+仅一方有标签+纵向FL+无损


摘要
保护用户隐私是机器学习中的一个重要问题，正如2018年5月在欧盟（EU）推出通用数据保护法规（GDPR）所证明的那样.GDPR旨在为用户提供更多控制权他们的个人数据促使我们通过数据共享来探索机器学习框架，而不会侵犯用户隐私。为了实现这一目标，在本文中，我们提出了一种新的无损隐私保护树增强系统，在联邦学习环境中称为SecureBoost。该联合学习系统允许学习过程在多方上联合进行，具有部分共同的用户样本但具有不同的特征集，这对应于垂直分区的虚拟数据集。 SecureBoost的一个优点是它提供与非隐私保护方法相同的准确度，同时不会泄露每个私有数据提供者的信息。我们理论上证明SecureBoost框架与其他非联合梯度树增强算法一样准确，它将数据集中到一个地方。此外，除了安全性证明之外，我们还讨论了使协议完全安全所需的条件。


SecureBoost
提出一种新的 基于隐私保护的模型无损 tree-boost 系统
允许学习过程在多方上面联合进行，具有部分共同点但不同特征集的用户样本  属于纵向联合学习

SecureBoost的突破点在于提供与非隐私保护相同的准确度，同时不会泄露私有数据信息

就是加了个安全，然后还跟别人一样的效果的算法。。。



传统FL是数据分布的框架：每一个数据是一方或者多方构成的样本子集，然后训练子模型

本文中考虑多方的设置，协同构建模型，同时保证用户隐私和数据机密

多方的设置：例如 用户方，机构方，公司方，平台方，等

本文的设置：数据包含多个参与者，每个参与者拥有一个数据子集，但是只有一个参与者会提供标签信息

大数据的表示垂直分割的，数据在各方的特征维度中分开，用户在不同方中有重叠

目标是允许各方为某些指定标签建立预测模型，同时禁止任何一方获取有关其他方数据的任何信息




谷歌在其Android云上引入了联邦学习框架（Konecny`等人2016）。基本思想是允许个人客户端加密他们的模型，然后在中心云站点上传和汇总。该站点的机器学习过程可以利用这些加密模型，同时不泄漏客户的信息。该框架适用于数据分区框架，其中每个分区对应于从一个或多个用户收集的数据样本的子集。
在本文中，我们考虑多方的一般设置，协同构建其机器学习模型，同时保护用户隐私和数据机密性。我们的设置如图2所示。我们考虑一组各方，每个方都拥有自己的一部分数据。我们可以将位于不同方的数据可视化为大数据表的子部分，该数据表是通过将不同方的所有数据联合而获得的。然后，每一方的数据都具有以下属性：
1.大数据表是垂直分割的，这样数据就可以在各方的特征维度中分开;
2.只有一个数据提供者拥有标签信息;
3.用户在不同方之间有部分重叠。
我们的目标是允许各方为某些指定标签建立预测模型，同时禁止任何一方获取有关其他方数据的任何信息。
我们的上述设置有几个优点。与大多数关于隐私保护数据挖掘和机器学习的现有工作相比，我们设置的复杂性显着增加。与数据水平分割的情况不同，上述设置需要更复杂的机制来分解每一方的损失函数（Vaidya 2008; Vaidya和Clifton 2005; Hardy等2017）。此外，在所有各方的每个模型构建过程中，只有一个数据提供者拥有标签信息。它要求我们提出一个安全的协议来指导学习过程，而不是在所有各方之间明确地共享标签信息。最后，数据机密性和隐私问题可以防止各方在构建模型时暴露自己的用户群体。因此，实体对齐也应以足够安全的方式进行。
在本文中，我们提出了一种新颖的端到端隐私保护树增强算法和框架，称为SecureBoost，以便在一个特定的环境中实现机器学习。与之前将用户维度上的数据分开的联合学习框架不同，我们的框架确保在数据在特征维度上的不同方之间分配时完成协作模型构建。我们的联邦学习框架分两步运作。首先，我们在保护隐私的约束下找到了各​​方之间的共同用户。然后，我们协作学习共享分类或回归模型，而不会相互泄露任何用户信息。我们总结了我们的主要贡献如下：
•我们在联邦学习环境中正式定义了一种新的隐私保护机器学习问题，而不是垂直分区数据。
•我们提出了一种方法，为每一方协同培训高质量的树木增强模型，同时保持培训数据对多方保密。我们在没有受信任的第三方参与的情况下经历了这个机器学习过程。
•最后也是重要的是，我们证明我们的方法是无损的，因为它与任何集中的非隐私保护方法一样准确，它将所有数据带到一个中心位置。
•此外，除了安全性证明之外，我们还讨论了使协议完全安全所需的条件。