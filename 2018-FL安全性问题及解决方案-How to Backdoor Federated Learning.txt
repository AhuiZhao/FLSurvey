
How to Backdoor Federated Learning
Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, Vitaly Shmatikov Cornell Tech
主要讲的联邦学习的安全性问题



摘要联合学习使成千上万的参与者能够构建深度学习模型，而无需彼此共享私人培训数据。例如，多个智能手机可以共同训练键盘的下一个字预测器，而不会显示个人用户键入的内容。我们证明联邦学习的任何参与者都可以在联合全局模型中引入隐藏的后门功能，例如，确保图像分类器将攻击者选择的标签分配给具有某些特征的图像，或者单词预测器完成某些句子。攻击者选择的单词。
我们设计并评估了基于模型替换的新模型中毒方法。在单轮联合学习中选择的攻击者可以使全局模型立即达到后门任务的100％准确性。我们在标准联合学习任务的不同假设下评估攻击，并表明它大大优于数据中毒。我们的通用约束和规模技术还通过在训练期间将逃避纳入攻击者的损失函数来规避基于异常检测的防御。

