

APPLIED FEDERATED LEARNING: IMPROVING GOOGLE KEYBOARD QUERY SUGGESTIONS 
Timothy Yang*, Galen Andrew*, Hubert Eichner* 
各个的另一波人
类型 ： 应用型
介绍了 谷歌键盘在FL上面的应用

联合学习是一种分布式的机器学习形式，其中训练数据和模型训练都是分散的。 在本文中，我们在商业，全球规模的设置中使用联合学习来训练，评估和部署模型，以提高虚拟键盘搜索建议质量，而无需直接访问底层用户数据。 我们描述了我们在联邦培训中的观察结果，将指标与实时部署进行比较，并提出了最终的质量提升。 总的来说，我们演示了联邦学习如何应用于端到端，以改善用户体验和增强用户隐私。

联邦学习（FL）[1,2,3]的引入实现了机器学习的新范例，其中训练数据和模型训练中涉及的大部分计算都是分散的。与传统的服务器端培训相比，用户数据聚合在中央服务器上进行培训，而FL则在最终用户设备上训练模型，同时仅在中央服务器上聚合短暂的参数更新。这对于隐私至关重要的环境尤其有利。
Google键盘（Gboard）是移动设备的虚拟键盘，在2018年安装量超过10亿.Gboard包括文本自动更正，下一字预测和单词补全等打字功能以及表情符号，如表情符号，GIF和贴纸（策划） ，表达的幻想和动画）。作为移动应用程序和键盘，Gboard具有独特的约束条件，非常适合于设备上的推理和培训。首先，作为可以访问用户在移动设备中输入的大部分内容的键盘应用程序，Gboard必须尊重用户的隐私。使用FL可以让我们在不收集用户敏感的原始输入的情况下训练机器学习模型。其次，延迟必须是最小的;在移动打字环境中，
及时提出建议是必要的，以保持相关性。通过FL进行设备推理和培训使我们能够最大限度地减少延迟并最大限度地提高隐私。
在本文中，我们在商业的全球规模设置中使用FL来训练和部署模型到生产中进行推理 - 所有这些都无法访问底层用户数据。我们的用例是搜索查询建议[4]：当用户输入文本时，Gboard使用基线模型来确定并可能表达与输入相关的搜索建议。例如，输入“让我们在查理吃饭”可能会显示一个网页查询建议，以搜索该名称附近的餐馆;其他类型的建议包括GIF和贴纸。在这里，我们通过使用FL训练的附加触发模型过滤来自基线模型的查询建议来改进该特征。通过将查询建议与FL和设备推理相结合，我们展示了对Gboard建议的质量改进，同时增强了用户隐私并尊重移动限制。
这只是FL的一个应用程序 - 开发人员从未访问过培训数据。其他工作还探讨了联邦多任务学习[5]，并行随机优化[6]和FL背景下的威胁行为者[7]。对于下一个单词预测，Gboard还使用FL来训练一个神经语言模型，该模型比使用传统的基于服务器的收集和训练训练的模型表现出更好的性能[8]。语言模型也经过FL和差异隐私训练，以进一步增强隐私[9,10]。通过利用联合学习，我们以隐私优势的方式继续改善用户体验。
本文的结构如下。在第2节中，我们介绍了FL，它的优点和支持系统基础设施。第3节描述了经过培训和部署的模型体系结构。第4部分深入介绍了我们使用FL培训模型的经验，包括培训要求和特性。在第5节中，我们在实时推理实验中部署联合训练模型并讨论结果，尤其是关于预期与实际指标的结果。




















——————————————————————————————
2019-Federated Learning Of Out-Of-Vocabulary Words

google的短文工作 不是前面那组人

研究谷歌键盘的应用

应用型文章，就是纯把FL用来训练 谷歌键盘的LSTM网络

实验部分主要是比较FedSGD的方法（属于一种延伸方法）
并没有和单机LSTM预测模型比较

证明可行性的意义较多，没有太多效果方面的优越性


摘要
我们证明了字符级复现神经网络能够在联邦学习设置下学习词汇外（OOV）单词，目的是扩展智能手机虚拟键盘的词汇量，而无需将敏感文本导出到服务器。 通过直接从关节后方绘制，可以从训练的生成模型中采样高频词。 我们在两种情况下研究该方法的可行性：（1）在来自流行社交网络网站的公开可用的非IID每用户数据集上使用模拟联合学习，（2）使用对用户移动设备上托管的数据的联合学习。 与设置（1）中的地面实况OOV字相比，该模型实现了良好的回忆和精确度。 通过（2）我们证明了这种方法的实用性，表明我们可以学习有意义的OOV字，具有良好的字符级预测精度和交叉熵损失。设备调度


1简介
Gboard  - 谷歌键盘 - 是一款用于触摸屏移动设备的虚拟键盘，自2018年起支持超过600种语言和超过10亿次安装.Gboard提供多种输入功能，包括点击和单词手势输入，自动 - 校正，单词完成和下一个单词预测。
从用户生成的数据中学习频繁输入的单词是移动键盘开发的重要组成部分。示例用法包括在出现时引入新的趋势词（名人姓名，流行文化词等），或者简单地补偿初始键盘实现中的遗漏，特别是对于低资源语言。
单词列表通常被称为“vocabulary”，可能也可能不是手工策划的。
词汇表中缺少的单词无法在键盘建议条上预测，无法进行手势输入，更烦人的是，即使正确输入也可以进行自动修正（Ouyang et al。，2017）。此外，由于延迟和可靠性原因，移动键盘模型在设备上运行。这意味着支持模型的词汇本身在尺寸上受到限制，例如每种语言几十万字。因此，在这个相当短的词汇表中发现并包含最有用的单词至关重要。词汇中没有的词通常被称为“词汇外”（OOV）词。请注意，词汇的概念不仅限于移动键盘。其他自然语言应用，例如神经机器翻译（NMT），依赖于词汇表来在端到端训练期间对单词进行编码。因此，学习OOV词及其排名是相当普遍的技术需求。
我们的工作重点是在环境中学习OOV单词，而无需在中央服务器上传输和存储敏感用户内容。当在设备上学习单词时，更容易确保。我们的工作建立在联邦学习（FL）的最新进展基础上（Konecny等人，2016; Yang等人，2018; Hard等人，2018），这是一种用于训练神经网络等模型的分散学习技术。用户的设备，仅将短暂的模型更新上载到服务器以进行聚合，并将用户的原始数据保留在其设备上。基于散列图，计数草图（Charikar等，2002）或尝试（Gunasinghe和Alahakoon，2012）的方法需要显着的适应才能在FL设置上运行（Zhu等，2019）。我们的工作建立在一个非常通用的神经网络FL框架之上，我们在设备上训练一个联合的基于字符的递归神经网络（RNN）。 OOV字是在干扰期间在服务器上采样的蒙特卡罗（详见2.1）。
虽然Federated Learning无需将原始用户资料（此处为OOV字样）上传到服务器，但仍存在意外记忆的隐私风险（如（Carlini等，2018）所示）。使用包括差别隐私在内的技术可以减轻这种风险，通常需要一定的准确性成本（McMahan等，2018）。探索这些权衡超出了本文的范围。
所提出的方法依赖于学习的概率模型，因此可能不会生成忠实训练的单词。它可能是“白日梦”的OOV词，也就是说，它提出了训练数据中从未见过的特征序列。它可能无法重新生成一些有趣的单词。证明该方法实用性的关键是回答：（1）白日梦词的出现频率如何？ （2）采样分布在数据集中表示真实词频的程度如何？针对这些问题，我们的贡献包括以下内容：
1.我们在具有模拟FL环境的公共Reddit评论数据集上训练提议的LSTM模型。 Reddit数据集包含每个条目的用户ID信息（用户的评论或帖子），可用于模拟FL的过程以从每个客户端的本地数据中学习。基于108个平行独立采样的总数，模拟的FL模型能够实现前105个独特单词的90.56％精度和81.22％召回率。
2.我们展示了使用真实的，设备上的FL设置从每日Gboard用户数据培训LSTM模型的可行性。 FL模型能够在用户的设备数据上达到55.8％的字符级前3预测准确度和2.35交叉熵。我们进一步表明，顶部采样的单词非常有意义，并且能够在实验时捕获我们知道在新闻中趋势的单词。




