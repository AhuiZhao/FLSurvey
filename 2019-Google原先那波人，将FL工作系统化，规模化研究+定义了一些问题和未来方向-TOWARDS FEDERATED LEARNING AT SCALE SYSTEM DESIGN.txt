2019-TOWARDS FEDERATED LEARNING AT SCALE: SYSTEM DESIGN

Google的工作，就是原先那波人的最新工作
bringing the code to the data， instead of the data to the code



key idea ：



摘要
联合学习是一种分布式机器学习方法，可以对大量分散数据进行模型训练。 我们基于TensorFlow在移动设备领域构建了可扩展的联邦学习生产系统。 在本文中，我们描述了由此产生的高级设计，描述了一些挑战及其解决方案，并触及了开放性问题和未来方向。

系统设计与规模化问题

本文中是联合学习 提出 在Android手机上面应用的一些问题定义，引导性的

他们主要的工作主要在于解决了许多实际的问题，
1、设备的可用性问题，复杂的本地数据分布方式（时区依赖性等）
2、可靠的设备连接和中断的执行
3、在变化的可用性下，跨设备的同步锁问题
4、终端设备有限的设备存储和计算资源问题

主要依赖于通信协议，设备和服务器层面解决
已经达到了可以投入业界的成熟态，并解决了数以千万级的设备中应用学习的问题，预计可以达到10亿级真实设备规模

官方的设定应用场景：
1、在线内容排序，推荐
2、在线键盘的内容建议
3、下个词预测


相关工作：
1、Alternative Approaches 一些其他人的FL设计相关研究
2、分布式ML
3、MapReduce

未来工作：
1、Bias 偏斜
2、收敛时间
3、设备调度算法 Device Scheduling
4、带宽
5、联邦计算





联邦学习（FL）（McMahan等，2017）是一种分布式机器学习方法，可以对驻留在移动电话等设备上的大量分散数据进行培训。 FL是“将代码引入数据而不是将数据引入代码”的更一般方法的一个实例，并解决了隐私，所有权和数据位置的基本问题。 McMahan＆Ramage（2017）给出了FL的一般描述，其理论已经在Konecny等人的研究中得到了探索。 （2016a）;麦克马汉等人。 （2017; 2018）。
联邦学习基础设施的基本设计决策是关注异步还是同步训练算法。虽然很多关于深度学习的成功工作都采用了异步训练，例如，Dean等人。 （2012年），最近出现了同步大批量培训的趋势，即使在数据中心也是如此（Goyal等，2017; Smith等，2018）。 McMahan等人的联邦平均算法。 （2017）采取类似的方法。此外，增强FL隐私保障的几种方法，包括差分隐私（McMahan等，2018）和安全聚合（Bonawitz等，2017），基本上需要一些固定设备上的同步概念，所以学习算法的服务器端仅消耗来自许多用户的更新的简单聚合。出于所有这些原因，我们选择了对同步轮的支持，同时通过我们随后描述的几种技术来减轻潜在的同步开销。因此，我们的系统可以运行大批量SGD样式算法以及联合平均算法，这是我们在生产中运行的主要算法;伪代码在附录B中给出，以确保完整性。
在本文中，我们报告了移动电话（Android）领域中此类算法的系统设计。这项工作仍处于早期阶段，我们没有解决所有问题，也无法全面讨论所有必需的组件。相反，我们试图描绘系统的主要组成部分，描述挑战，并确定未解决的问题，希望这将有助于进一步激发系统研究。
我们的系统使用TensorFlow（Abadi等人，2016）训练深度神经网络，对存储在手机上的数据永远不会离开设备。权重在云中与联合平均相结合，构建一个全局模型，推送回电话进行推理。安全聚合的实现（Bonawitz等，2017）确保在全球范围内，来自电话的个人更新是不可思议的。该系统已应用于大规模应用，例如在电话键盘领域。
我们的工作解决了许多实际问题：设备可用性与复杂方式的本地数据分布相关（例如，时区依赖性）;不可靠的设备连接和中断的执行;跨越具有不同可用性的设备执行锁步执行的编排;和有限的设备存储和计算资源。这些问题在通信协议，设备和服务器级别得到解决。我们已经达到了足以将系统部署到生产中的成熟状态，并解决了数以千万计的真实设备中的应用学习问题;我们预计设备数量达到数十亿的用途。



