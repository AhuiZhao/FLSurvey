2019-Federated Learning Of Out-Of-Vocabulary Words

google的短文工作 不是前面那组人

研究谷歌键盘的应用

应用型文章，就是纯把FL用来训练 谷歌键盘的LSTM网络

实验部分主要是比较FedSGD的方法（属于一种延伸方法）
并没有和单机LSTM预测模型比较

证明可行性的意义较多，没有太多效果方面的优越性


摘要
我们证明了字符级复现神经网络能够在联邦学习设置下学习词汇外（OOV）单词，目的是扩展智能手机虚拟键盘的词汇量，而无需将敏感文本导出到服务器。 通过直接从关节后方绘制，可以从训练的生成模型中采样高频词。 我们在两种情况下研究该方法的可行性：（1）在来自流行社交网络网站的公开可用的非IID每用户数据集上使用模拟联合学习，（2）使用对用户移动设备上托管的数据的联合学习。 与设置（1）中的地面实况OOV字相比，该模型实现了良好的回忆和精确度。 通过（2）我们证明了这种方法的实用性，表明我们可以学习有意义的OOV字，具有良好的字符级预测精度和交叉熵损失。设备调度


1简介
Gboard  - 谷歌键盘 - 是一款用于触摸屏移动设备的虚拟键盘，自2018年起支持超过600种语言和超过10亿次安装.Gboard提供多种输入功能，包括点击和单词手势输入，自动 - 校正，单词完成和下一个单词预测。
从用户生成的数据中学习频繁输入的单词是移动键盘开发的重要组成部分。示例用法包括在出现时引入新的趋势词（名人姓名，流行文化词等），或者简单地补偿初始键盘实现中的遗漏，特别是对于低资源语言。
单词列表通常被称为“vocabulary”，可能也可能不是手工策划的。
词汇表中缺少的单词无法在键盘建议条上预测，无法进行手势输入，更烦人的是，即使正确输入也可以进行自动修正（Ouyang et al。，2017）。此外，由于延迟和可靠性原因，移动键盘模型在设备上运行。这意味着支持模型的词汇本身在尺寸上受到限制，例如每种语言几十万字。因此，在这个相当短的词汇表中发现并包含最有用的单词至关重要。词汇中没有的词通常被称为“词汇外”（OOV）词。请注意，词汇的概念不仅限于移动键盘。其他自然语言应用，例如神经机器翻译（NMT），依赖于词汇表来在端到端训练期间对单词进行编码。因此，学习OOV词及其排名是相当普遍的技术需求。
我们的工作重点是在环境中学习OOV单词，而无需在中央服务器上传输和存储敏感用户内容。当在设备上学习单词时，更容易确保。我们的工作建立在联邦学习（FL）的最新进展基础上（Konecny等人，2016; Yang等人，2018; Hard等人，2018），这是一种用于训练神经网络等模型的分散学习技术。用户的设备，仅将短暂的模型更新上载到服务器以进行聚合，并将用户的原始数据保留在其设备上。基于散列图，计数草图（Charikar等，2002）或尝试（Gunasinghe和Alahakoon，2012）的方法需要显着的适应才能在FL设置上运行（Zhu等，2019）。我们的工作建立在一个非常通用的神经网络FL框架之上，我们在设备上训练一个联合的基于字符的递归神经网络（RNN）。 OOV字是在干扰期间在服务器上采样的蒙特卡罗（详见2.1）。
虽然Federated Learning无需将原始用户资料（此处为OOV字样）上传到服务器，但仍存在意外记忆的隐私风险（如（Carlini等，2018）所示）。使用包括差别隐私在内的技术可以减轻这种风险，通常需要一定的准确性成本（McMahan等，2018）。探索这些权衡超出了本文的范围。
所提出的方法依赖于学习的概率模型，因此可能不会生成忠实训练的单词。它可能是“白日梦”的OOV词，也就是说，它提出了训练数据中从未见过的特征序列。它可能无法重新生成一些有趣的单词。证明该方法实用性的关键是回答：（1）白日梦词的出现频率如何？ （2）采样分布在数据集中表示真实词频的程度如何？针对这些问题，我们的贡献包括以下内容：
1.我们在具有模拟FL环境的公共Reddit评论数据集上训练提议的LSTM模型。 Reddit数据集包含每个条目的用户ID信息（用户的评论或帖子），可用于模拟FL的过程以从每个客户端的本地数据中学习。基于108个平行独立采样的总数，模拟的FL模型能够实现前105个独特单词的90.56％精度和81.22％召回率。
2.我们展示了使用真实的，设备上的FL设置从每日Gboard用户数据培训LSTM模型的可行性。 FL模型能够在用户的设备数据上达到55.8％的字符级前3预测准确度和2.35交叉熵。我们进一步表明，顶部采样的单词非常有意义，并且能够在实验时捕获我们知道在新闻中趋势的单词。




