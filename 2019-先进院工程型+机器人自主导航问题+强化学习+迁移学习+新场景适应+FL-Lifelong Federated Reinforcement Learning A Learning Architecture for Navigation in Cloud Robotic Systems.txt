2019-Lifelong Federated Reinforcement Learning: A Learning Architecture for Navigation in Cloud Robotic Systems

深圳先进院，云计算实验室的工作
很工程的一个工作

key idea
先进院工程型+机器人自主导航问题+强化学习+迁移学习+新场景适应+FL

一个与应用领域交叉的项目：与云机器人算法领域结合（自主导航问题）
终身联邦强化学习LFRL，提出知识融合算法，用于升级部署在云上的共享模型。
然后介绍了LFRL中有效的迁移学习方法，适合云机器人系统

摘要 - 本文的动机是如何使机器人融合并转移经验，以便有效利用先验知识，快速适应新环境。 为了解决这个问题，我们提出了云机器人系统导航的学习架构：终身联邦强化学习（LFRL）。 在工作中，我们提出了一种知识融合算法，用于升级部署在云上的共享模型。 然后，介绍了LFRL中有效的转移学习方法。 LFRL与人类认知科学一致，非常适合云机器人系统。 实验表明，LFRL大大提高了机器人导航强化学习的效率。 云机器人系统部署还表明LFRL能够融合先前的知识。 此外，我们还发布了一个云机器人导航学习网站，以提供基于LFRL的服务：www.shared-robotics.com。




行文逻辑：
解决云机器人的自主导航问题
方式：用强化学习
但是仍然存在一些问题：如减少训练时间，长时间存储数据，分离计算，快速适应新环境等[1]。

强化学习（RL）算法被广泛用于解决导航任务。 RL是一种反应式导航方法，是提高移动机器人在未知环境中的实时性和适应性的重要手段。然而，在导航强化学习的应用中仍然存在一些问题，如减少训练时间，长时间存储数据，分离计算，快速适应新环境等[1]。

创新点：
1、解决了快速适应新环境的问题，利用先验知识高效扩展知识，通过共享运动轨迹，统一控制学习策略的方式强化。

我们解决了如何使机器人在新环境中高效学习并扩展经验以便他们能够有效利用先验知识的问题。我们专注于云计算和云机器人技术[2]，它可以通过促进共享轨迹，控制集体机器人学习的政策和结果的过程来增强机器人系统。受人类认知科学的启发，我们提出了图2所示的终身联邦强化学习（LFRL）架构来实现这一目标。利用可扩展的架构和知识融合算法，LFRL在云机器人导航的强化学习中实现了极高的效率。 LFRL使机器人能够记住他们所学到的知识以及其他机器人通过云机器人系统学到的知识。

贡献点：
1、LFRL框架
2、知识融合算法
3、引入迁移学习
4、他们工作有落地实例